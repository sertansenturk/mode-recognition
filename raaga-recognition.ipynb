{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../ModeTonicEstimation/')\n",
    "\n",
    "from fileoperations.fileoperations import getFileNamesInDir\n",
    "\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from ModeTonicEstimation import Chordia\n",
    "from ModeTonicEstimation import Evaluator as ev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = int('1') # this is the input to be taken by the cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I/O\n",
    "base_dir = '../../test_datasets/RagaRecognition_journal'\n",
    "tradition_dir = 'hindustani'  # possible: makam, carnatic, hindustani\n",
    "num_class_dir = '30_classes'  # possible: 5, 10, 15, 20, 25, 30\n",
    "\n",
    "data_dir = os.path.join(base_dir, tradition_dir)\n",
    "\n",
    "experiment_dir = os.path.join(base_dir, 'fileLists', tradition_dir, num_class_dir)\n",
    "experiment_file = getFileNamesInDir(experiment_dir, keyword='*.json')[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiments = json.load(open(experiment_file, 'r'))\n",
    "\n",
    "audio_files = [os.path.join(data_dir,e[2]) for e in experiments]\n",
    "pitch_files = [os.path.join(data_dir,e[2]+'.pitch') for e in experiments]\n",
    "audio_mbids = [e[0] for e in experiments]\n",
    "audio_tonics = [np.loadtxt(p+'.tonicFine') for p in audio_files]\n",
    "audio_labels = [e[1] for e in experiments]\n",
    "\n",
    "unique_labels = set(audio_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate objects\n",
    "evaluator = ev.Evaluator()\n",
    "che = Chordia.Chordia(step_size=10, smooth_factor=15,\n",
    "                      chunk_size=0, threshold=0.5, \n",
    "                      overlap=0, frame_rate=196.0/44100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# divide training & testing (leave-one-out)\n",
    "training_files = copy.deepcopy(audio_files)\n",
    "training_pitch_files = copy.deepcopy(pitch_files)\n",
    "training_mbids = copy.deepcopy(audio_mbids)\n",
    "training_tonics = copy.deepcopy(audio_tonics)\n",
    "training_labels = copy.deepcopy(audio_labels)\n",
    "\n",
    "# pop the test audio from the training\n",
    "test_file = training_files.pop(idx)\n",
    "test_pitch_file = training_pitch_files.pop(idx)\n",
    "test_mbid = training_mbids.pop(idx)\n",
    "test_tonic = training_tonics.pop(idx)\n",
    "test_label = training_labels.pop(idx)\n",
    "\n",
    "model_save_dir = os.path.join(experiment_dir, 'chordia', test_mbid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training label: 2ed9379f-14c9-49af-8e4d-f9b63e96801f\n",
      "   Training label: 64e5fb9e-5569-4e80-8e6c-f543af9469c7\n",
      "   Training label: 0b3bbf97-0ec3-41da-add4-722d87329ec3\n",
      "   Training label: a99e07d5-20a0-467b-8dcd-aa5a095177fd\n",
      "   Training label: 595de771-fcc2-414c-9df6-ae4ffd898549\n",
      "   Training label: 7591faad-e68a-4550-b675-8082842c6056\n",
      "   Training label: e771a74d-545d-41d5-816b-43403a818b0c\n",
      "   Training label: 62b79291-73b0-4c77-a353-0f8bc6ed8362\n",
      "   Training label: 48b37bed-e847-4882-8a01-5c721e07f07d\n",
      "   Training label: f7fddfc0-8c1d-4dd2-90d5-5d51a99d61f8\n",
      "   Training label: 3eb7ba30-4b94-432e-9618-875ee57e01ab\n",
      "   Training label: 1b05a564-059f-445b-b325-cf26318367e3\n",
      "   Training label: f6432fec-e9c2-4b09-9e73-c46086cbd8ea\n",
      "   Training label: 54c4214c-05b9-4acc-8f77-6d5786e43a2e\n",
      "   Training label: 40dbe1db-858f-4366-bef8-9076eb67340d\n",
      "   Training label: 118401e7-8de8-4d81-9d8e-8070889e3fa8\n",
      "   Training label: a7d98897-e2fe-4d75-b9dc-e5b4dc88e1c6\n",
      "   Training label: 6f13484e-6fdd-402d-baf3-3835835454d0\n",
      "   Training label: 1e7de02f-e77f-405a-a033-f31117aaf955\n",
      "   Training label: b143adaa-f1a6-4de4-8985-a5bd35e96279\n",
      "   Training label: a9ee554f-f146-43e9-b2d0-9bb31fd4b57d\n",
      "   Training label: ba3242d0-8d40-4d93-865e-d2e2497ea2a8\n",
      "   Training label: 46997b02-f09c-4969-8138-4e1861f61967\n",
      "   Training label: 290674e0-d94c-41c1-ad99-f65fa22a1447\n",
      "   Training label: fa28470c-d413-44c7-94da-181f530cbfdd\n",
      "   Training label: dd59147d-8775-44ff-a36b-0d9f15b31319\n",
      "   Training label: d9c603fa-875f-4b84-b851-c6a345427898\n",
      "   Training label: ecd04ceb-b46c-47fc-9045-84ac9160e527\n",
      "   Training label: 93c73081-bdf8-4eca-b325-d736b71e9b4b\n",
      "   Training label: 063ea5a0-23b1-4bb5-8537-3d924fe8ebb3\n"
     ]
    }
   ],
   "source": [
    "# Training \n",
    "models = dict()\n",
    "for label in unique_labels:\n",
    "    print '   Training label: ' + label\n",
    "    model_file = os.path.join(model_save_dir, label+'.json')\n",
    "    try:\n",
    "        models[label] = che.load_collection(label, model_save_dir)\n",
    "    except IOError:\n",
    "        models[label] = che.train(label, training_pitch_files, training_tonics, \n",
    "                                  metric='pcd', save_dir = model_save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing audio: 9117fa28-df28-4bb8-a0e3-b70e60fed262\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Testing \n",
    "print 'Testing audio: ' + test_mbid\n",
    "res = che.estimate(test_pitch_file, mode_names=list(unique_labels), \n",
    "                   mode_dir=model_save_dir, est_mode=True, \n",
    "                   distance_method='bhat',\n",
    "                   metric='pcd', tonic_freq=test_tonic)[0]\n",
    "\n",
    "print res == test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # get the data into appropriate format\n",
    "# [pitch_paths, pitch_base, pitch_fname] = fo.getFileNamesInDir(data_dir, '.pitch')\n",
    "# tonic_paths = [os.path.splitext(p)[0] + '.tonic' for p in pitch_paths]\n",
    "# mode_labels = []\n",
    "# for p in pitch_base:\n",
    "#     for r in modes:\n",
    "#         if r in p:\n",
    "#             mode_labels.append(r)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # make the data a single dictionary for housekeeping\n",
    "# data = []\n",
    "# for p, f, t, r in zip(pitch_paths, pitch_fname, tonic_paths, mode_labels):\n",
    "#     data.append({'file':p, 'name':os.path.splitext(f)[0],\n",
    "#                'tonic':float(np.loadtxt(t)), 'mode':r})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # experiments\n",
    "# results = dict()\n",
    "# for key, fold in folds.iteritems():\n",
    "#     # Training \n",
    "#     print key\n",
    "#     models = dict()\n",
    "#     for cur_mode in modes:\n",
    "#         [file_list, tonic_list] = zip(*[(rec['file'], rec['tonic']) for rec in fold['train']\n",
    "#                                         if rec['mode'] == cur_mode])\n",
    "#         models[cur_mode] = che.train(cur_mode, file_list, tonic_list, metric='pcd', \n",
    "#                                      save_dir = os.path.join(train_savefolder, key))\n",
    "                                     \n",
    "#     # Raag Recognition\n",
    "#     results[key] = []\n",
    "#     for rec in fold['test']:\n",
    "#         rec['pitch'] = np.loadtxt(rec['file'])[:,1]\n",
    "#         res = che.estimate(rec['pitch'], mode_names=modes, \n",
    "#                            mode_dir=os.path.join(train_savefolder, key), \n",
    "#                            est_tonic=False, est_mode=True, distance_method='bhat',\n",
    "#                            metric='pcd', ref_freq=rec['tonic'])[0]\n",
    "\n",
    "#         # evaluate\n",
    "#         results[key].append(evaluator.mode_evaluate(rec['file'], res, rec['mode']))\n",
    "\n",
    "#     print key + \": \" + str(100*np.mean([r['mode_eval'] for r in results[key]])) + '%'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
