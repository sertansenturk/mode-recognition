{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../Research/MTG/ModeTonicEstimation/ModeTonicEstimation/')\n",
    "\n",
    "from Chordia import Chordia\n",
    "import ModeFunctions as mf\n",
    "import PitchDistribution\n",
    "from fileOperations import getFileNamesInDir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I/O\n",
    "base_dir = '../sankalp/'\n",
    "tradition_dir = 'hindustani'  # possible: makam, carnatic, hindustani\n",
    "num_class_dir = '5_classes'  # possible: 5, 10, 15, 20, 25, 30\n",
    "\n",
    "data_dir = os.path.join(base_dir, tradition_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define feature extraction code: compute the pcd's of all recordings\n",
    "def getPCD(pitchfile, tonic_freq, source):\n",
    "    pitch_track = np.loadtxt(pitchfile)\n",
    "    if pitch_track.ndim > 1:  # assume the first col is time, the second is pitch and the rest is labels etc\n",
    "        pitch_track = pitch_track[:,1]\n",
    "\n",
    "    # Each chunk is converted to cents\n",
    "    pitch_cent = mf.hz_to_cent(pitch_track, ref_freq=tonic_freq)\n",
    "\n",
    "    # PitchDistribution of the current chunk is generated\n",
    "    pd = mf.generate_pd(pitch_cent, ref_freq=tonic_freq, \n",
    "                        smooth_factor=10.0, step_size=10.0,\n",
    "                        source=source)\n",
    "    return mf.generate_pcd(pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment metadata initiated\n",
    "results = {'true_raag':[], 'estimated_raag':[], 'eval':[], 'recording_mbid':[], 'accuracy':0}\n",
    "experiment_dir = os.path.join(base_dir, 'fileLists', tradition_dir, num_class_dir)\n",
    "experiment_file = getFileNamesInDir(experiment_dir, keyword='*.json')[0][0]\n",
    "experiments = json.load(open(experiment_file, 'r'))\n",
    "\n",
    "# Paths, PCDs, Tonics are loaded\n",
    "audio_names = [data_dir+'/'+e[2] for e in experiments]\n",
    "pitch_files = [(data_dir+'/'+e[2]+'.pitch') for e in experiments]\n",
    "pcd_files = [(data_dir+'/'+e[2]+'.pcd') for e in experiments]\n",
    "audio_mbids = [e[0] for e in experiments]\n",
    "audio_tonics = [np.loadtxt(str(p+'.tonic')) for p in audio_names]\n",
    "audio_labels = [e[1] for e in experiments]\n",
    "unique_labels = set(audio_labels)\n",
    "\n",
    "# instantiate objects\n",
    "che = Chordia(step_size=10, smooth_factor=15,\n",
    "                      chunk_size=0, threshold=0.5, \n",
    "                      overlap=0, frame_rate=196.0/44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PCD extraction\n",
    "pcds = []\n",
    "for i, (pf, tf, am, al, pcdf) in enumerate(zip(pitch_files, audio_tonics, audio_mbids, audio_labels, pcd_files)):\n",
    "    # print str(i) + \" Getting PCD of \" + am\n",
    "    \n",
    "    if not os.path.isfile(pcdf):\n",
    "        pcd_temp = getPCD(pf, tf, am)\n",
    "        pcd_temp.save(pcdf)\n",
    "        \n",
    "        pcds.append({'pcd': pcd_temp, 'label': al, 'audio_mbid': am})\n",
    "    else:\n",
    "        pcds.append({'pcd':PitchDistribution.load(pcdf), 'label': al, 'audio_mbid': am})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/50\n",
      "1/50\n",
      "2/50\n",
      "3/50\n",
      "4/50\n",
      "5/50\n",
      "6/50\n",
      "7/50\n",
      "8/50\n",
      "9/50\n",
      "10/50\n",
      "11/50\n",
      "12/50\n",
      "13/50\n",
      "14/50\n",
      "15/50\n",
      "16/50\n",
      "17/50\n",
      "18/50\n",
      "19/50\n",
      "20/50\n",
      "21/50\n",
      "22/50\n",
      "23/50\n",
      "24/50\n",
      "25/50\n",
      "26/50\n",
      "27/50\n",
      "28/50\n",
      "29/50\n",
      "30/50\n",
      "31/50\n",
      "32/50\n",
      "33/50\n",
      "34/50\n",
      "35/50\n",
      "36/50\n",
      "37/50\n",
      "38/50\n",
      "39/50\n",
      "40/50\n",
      "41/50\n",
      "42/50\n",
      "43/50\n",
      "44/50\n",
      "45/50\n",
      "46/50\n",
      "47/50\n",
      "48/50\n",
      "49/50\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0,len(audio_names)):\n",
    "    print(str(idx)+'/'+str(len(audio_names)))\n",
    "    # divide training & testing (leave-one-out)\n",
    "    training_names = copy.deepcopy(audio_names)\n",
    "    training_pitch_files = copy.deepcopy(pitch_files)\n",
    "    training_pcd_files = copy.deepcopy(pcd_files)\n",
    "    training_pcds = copy.deepcopy(pcds)\n",
    "    training_mbids = copy.deepcopy(audio_mbids)\n",
    "    training_tonics = copy.deepcopy(audio_tonics)\n",
    "    training_labels = copy.deepcopy(audio_labels)\n",
    "\n",
    "    # pop the test audio from the training\n",
    "    test_name = training_names.pop(idx)\n",
    "    test_pitch_file = training_pitch_files.pop(idx)\n",
    "    test_pcd_file = training_pcd_files.pop(idx)\n",
    "    test_pcds = training_pcds.pop(idx)\n",
    "    test_mbid = training_mbids.pop(idx)\n",
    "    test_tonic = training_tonics.pop(idx)\n",
    "    test_label = training_labels.pop(idx)\n",
    "\n",
    "    model_save_dir = os.path.join(experiment_dir, 'chordia', test_mbid)\n",
    "    \n",
    "    # Training: get the pcds of each raga\n",
    "    models = dict()\n",
    "    for pcd_dict in training_pcds:\n",
    "        if pcd_dict['label'] not in models.keys():\n",
    "            models[pcd_dict['label']] = [pcd_dict['pcd']]\n",
    "        else:\n",
    "            models[pcd_dict['label']].append(pcd_dict['pcd'])\n",
    "            che.save_model(models[pcd_dict['label']], model_save_dir, pcd_dict['label'])\n",
    "            \n",
    "    # Testing \n",
    "    res = che.mode_estimate(test_pitch_file, test_tonic, list(unique_labels), \n",
    "                            mode_dir=model_save_dir, distance_method='bhat',\n",
    "                            metric='pcd')\n",
    "    \n",
    "    results['true_raag'].append(test_label)\n",
    "    results['estimated_raag'].append(res)\n",
    "    results['eval'].append(int(res == test_label))\n",
    "    results['recording_mbid'].append(test_mbid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "results['accuracy'] = 1.0 * sum(results['eval']) / len(results['eval'])\n",
    "print(results['accuracy'])\n",
    "json.dump(results, open(tradition_dir+'_'+num_class_dir+'_results.json', 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
