{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../ModeTonicRecognition/')\n",
    "\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from extras import foldGeneration\n",
    "from extras import fileOperations as fo\n",
    "import numpy as np\n",
    "import ChordiaEstimation\n",
    "import Evaluator as ev\n",
    "from sklearn import cross_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I/O\n",
    "experiment_dir = data_dir = '../../experiments/raag-recognition/'\n",
    "data_dir = os.path.join(experiment_dir,'data')\n",
    "modes = fo.getModeNames(data_dir)\n",
    "\n",
    "fold_savefile = os.path.join(experiment_dir, 'folds.json')\n",
    "train_savefolder = os.path.join(experiment_dir, 'models')\n",
    "results_savefolder = os.path.join(experiment_dir, 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate objects\n",
    "evaluator = ev.Evaluator()\n",
    "che = ChordiaEstimation.ChordiaEstimation(step_size=10, smooth_factor=15, \n",
    "                                          chunk_size=120, threshold=0.5, \n",
    "                                          overlap=0, frame_rate=128.0/44100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the data into appropriate format\n",
    "[pitch_paths, pitch_base, pitch_fname] = fo.getFileNamesInDir(data_dir, '.pitch')\n",
    "tonic_paths = [os.path.splitext(p)[0] + '.tonic' for p in pitch_paths]\n",
    "mode_labels = []\n",
    "for p in pitch_base:\n",
    "    for r in modes:\n",
    "        if r in p:\n",
    "            mode_labels.append(r)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make the data a single dictionary for housekeeping\n",
    "data = []\n",
    "for p, f, t, r in zip(pitch_paths, pitch_fname, tonic_paths, mode_labels):\n",
    "    data.append({'file':p, 'name':os.path.splitext(f)[0],\n",
    "               'tonic':float(np.loadtxt(t)), 'mode':r})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stratified 14 fold \n",
    "mode_idx = [modes.index(m) for m in [d['mode'] for d in data]]\n",
    "skf = cross_validation.StratifiedKFold(mode_idx, n_folds=14)\n",
    "\n",
    "folds = dict()\n",
    "for ff, fold in enumerate(skf):\n",
    "    folds['fold' + str(ff)] = {'train': [], 'test': []}\n",
    "    for tr_idx in fold[0]:\n",
    "        folds['fold' + str(ff)]['train'].append(data[tr_idx])\n",
    "    for te_idx in fold[1]:\n",
    "        folds['fold' + str(ff)]['test'].append(data[te_idx])\n",
    "        \n",
    "with open(fold_savefile, 'w') as f:\n",
    "    json.dump(folds, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold8\n",
      "fold8: 80.0%\n",
      "fold9\n",
      "fold9: 100.0%\n",
      "fold2\n",
      "fold2: 90.0%\n",
      "fold3\n",
      "fold3: 100.0%\n",
      "fold0\n",
      "fold0: 80.0%\n",
      "fold1\n",
      "fold1: 70.0%\n",
      "fold6\n",
      "fold6: 80.0%\n",
      "fold7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f92cac2f6605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                         if rec['mode'] == cur_mode])\n\u001b[1;32m     10\u001b[0m         models[cur_mode] = che.train(cur_mode, file_list, tonic_list, metric='pcd', \n\u001b[0;32m---> 11\u001b[0;31m                                      save_dir = os.path.join(train_savefolder, key))\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Raag Recognition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sertansenturk/Documents/notaIcra/code/ModeTonicRecognition/ChordiaEstimation.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode_name, pt_files, tonic_freqs, metric, save_dir)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mpf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtonic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtonic_freqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                         \u001b[0mpitch_track\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mpitch_track\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# assume the first col is time, the second is pitch and the rest is labels etc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                 \u001b[0mpitch_track\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpitch_track\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sertansenturk/Documents/notaIcra/virtualenvs/phd/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;31m# Parse each line, including the first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirst_line\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m             \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# experiments\n",
    "results = dict()\n",
    "for key, fold in folds.iteritems():\n",
    "    # Training \n",
    "    print key\n",
    "    models = dict()\n",
    "    for cur_mode in modes:\n",
    "        [file_list, tonic_list] = zip(*[(rec['file'], rec['tonic']) for rec in fold['train']\n",
    "                                        if rec['mode'] == cur_mode])\n",
    "        models[cur_mode] = che.train(cur_mode, file_list, tonic_list, metric='pcd', \n",
    "                                     save_dir = os.path.join(train_savefolder, key))\n",
    "                                     \n",
    "    # Raag Recognition\n",
    "    results[key] = []\n",
    "    for rec in fold['test']:\n",
    "        rec['pitch'] = np.loadtxt(rec['file'])[:,1]\n",
    "        res = che.estimate(rec['pitch'], mode_names=modes, \n",
    "                           mode_dir=os.path.join(train_savefolder, key), \n",
    "                           est_tonic=False, est_mode=True, distance_method='bhat',\n",
    "                           metric='pcd', ref_freq=rec['tonic'])[0]\n",
    "\n",
    "        # evaluate\n",
    "        results[key].append(evaluator.mode_evaluate(rec['file'], res, rec['mode']))\n",
    "\n",
    "    print key + \": \" + str(100*np.mean([r['mode_eval'] for r in results[key]])) + '%'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
